# Applying Self-Supervised Learning to Medicine: Review of the State of the Art and Medical Implementations
(A Review of Self-Supervised Learning in Medicine)

Selected highlights from the 2021 Self-Supervised Learning Review [https://doi.org/10.3390/informatics8030059] that reviewed over **3,012 works related to the field of self-supervised learning**. 

Table of contents
=================
- [Applying Self-Supervised Learning to Medicine: Review of the State of the Art and Medical Implementations](#applying-self-supervised-learning-to-medicine--review-of-the-state-of-the-art-and-medical-implementations)
  * [List of papers for Pixel-to-Scalar Self-Supervised Learning](#list-of-papers-for-pixel-to-scalar-self-supervised-learning)
  * [List of papers for Pixel-to-Scalar Self-Supervised Learning](#list-of-papers-for-pixel-to-scalar-self-supervised-learning-1)
  * [List of papers for Adversarial Self-Supervised Learning](#list-of-papers-for-adversarial-self-supervised-learning)
  * [List of papers for Contrastive Self-Supervised Learning](#list-of-papers-for-contrastive-self-supervised-learning)
- [Complete details of all manuscripts that were reviewed](#complete-details-of-all-manuscripts-that-were-reviewed)

## List of papers for Pixel-to-Scalar Self-Supervised Learning
| Method                      | Work                                                                                                                                                           | Used By How Many Works |
| --------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------- |
| Context Prediction          | [LINK](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Doersch_Unsupervised_Visual_Representation_ICCV_2015_paper.pdf)                       | 1487                   |
| Context Free Network        | [LINK](https://link.springer.com/chapter/10.1007/978-3-319-46466-4_5)                                                                                          | 1251                   |
| DeepPermNet                 | [LINK](https://openaccess.thecvf.com/content_cvpr_2017/papers/Santa_Cruz_DeepPermNet_Visual_Permutation_CVPR_2017_paper.pdf)                                   | 69                     |
| RotNet                      | [LINK](https://arxiv.org/pdf/1803.07728.pdf)                                                                                                                   | 1166                   |
| S4L                         | [LINK](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhai_S4L_Self-Supervised_Semi-Supervised_Learning_ICCV_2019_paper.pdf)                           | 310                    |
| Rotation Feature Decoupling | [LINK](https://openaccess.thecvf.com/content_CVPR_2019/papers/Feng_Self-Supervised_Representation_Learning_by_Rotation_Feature_Decoupling_CVPR_2019_paper.pdf) | 74                     |
| Cross and Learn             | [LINK](https://link.springer.com/chapter/10.1007/978-3-030-12939-2_17)                                                                                         | 47                     |
| Egomotion                   | [LINK](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Agrawal_Learning_to_See_ICCV_2015_paper.pdf)                                          | 513                    |

## List of papers for Pixel-to-Scalar Self-Supervised Learning
| Method                  | Work                                                                                                                           | Used By How Many Works |
| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------ | ---------------------- |
| Inpainting              | [LINK](https://openaccess.thecvf.com/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf)             | 3210                   |
| Colorization            | [LINK](https://link.springer.com/chapter/10.1007/978-3-319-46493-0_35)                                                         | 635                    |
| Colorization            | [LINK](https://link.springer.com/chapter/10.1007/978-3-319-46487-9_40)                                                         | 2043                   |
| Split-Brain Autoencoder | [LINK](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Split-Brain_Autoencoders_Unsupervised_CVPR_2017_paper.pdf) | 419                    |
| Multi-Task SSL          | [LINK](https://openaccess.thecvf.com/content_ICCV_2017/papers/Doersch_Multi-Task_Self-Supervised_Visual_ICCV_2017_paper.pdf)   | 418                    |

## List of papers for Adversarial Self-Supervised Learning
| Method                       | Work                                                                                                                                     | Used By How Many Works |
| ---------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- | ---------------------- |
| Adversarial Feature Learning | [LINK](https://arxiv.org/pdf/1605.09782.pdf)                                                                                             | 1353                   |
| InfoGAN                      | [LINK](https://proceedings.neurips.cc/paper/2016/file/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Paper.pdf)                                        | 3112                   |
| Artifact Detection           | [LINK](https://openaccess.thecvf.com/content_cvpr_2018/papers/Jenni_Self-Supervised_Feature_Learning_CVPR_2018_paper.pdf)                | 76                     |
| Auxiliary Rotation Loss      | [LINK](https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Self-Supervised_GANs_via_Auxiliary_Rotation_Loss_CVPR_2019_paper.pdf) | 136                    |

## List of papers for Contrastive Self-Supervised Learning
| Method            | Work                                                                                                                                                       | Used By How Many Works |
| ----------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------- |
| Local Aggregation | [LINK](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhuang_Local_Aggregation_for_Unsupervised_Learning_of_Visual_Embeddings_ICCV_2019_paper.pdf) | 197                    |
| CPC               | [LINK](http://proceedings.mlr.press/v119/henaff20a/henaff20a.pdf)                                                                                          | 490                    |
| SimCLR            | [LINK](http://proceedings.mlr.press/v119/chen20j/chen20j.pdf)                                                                                              | 2161                   |
| MoCo              | [LINK](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf)    | 1720                   |

## List of papers applied to medicine
| Method            | Work                                                                                                                                                       |
| ----------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------- |
| Local Aggregation | [LINK](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhuang_Local_Aggregation_for_Unsupervised_Learning_of_Visual_Embeddings_ICCV_2019_paper.pdf) |           
| CPC               | [LINK](http://proceedings.mlr.press/v119/henaff20a/henaff20a.pdf)                                                                                          |
| SimCLR            | [LINK](http://proceedings.mlr.press/v119/chen20j/chen20j.pdf)                                                                                              |
| MoCo              | [LINK](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf)    |                  |

# Complete details of all manuscripts that were reviewed
| Database          | Keyword                  | Details                                                          |
| ----------------- | ------------------------ | ---------------------------------------------------------------- |
| Google scholar    | Self-supervised learning | [LINK](Markdown%20Files/gs%20self-supervised%20learning.md)      |
| Google scholar    | Selfsupervised learning  | [LINK](Markdown%20Files/gs%20selfsupervised%20learning.md)       |
| Google scholar    | Representation learning  | [LINK](Markdown%20Files/gs%20representation%20learning.md)       |
| CrossRef          | Self-supervised learning | [LINK](Markdown%20Files/cf%20self-supervised%20learning.md)      |
| CrossRef          | Selfsupervised learning  | [LINK](Markdown%20Files/cf%20selfsupervised%20learning.md)       |
| CrossRef          | Representation learning  | [LINK](Markdown%20Files/cf%20representation%20learning.md)       |
| Scopus            | Self-supervised learning | [LINK](Markdown%20Files/sc%20self-supervised%20learning.md)      |
| Scopus            | Selfsupervised learning  | [LINK](Markdown%20Files/sc%20selfsupervised%20learning.md)       |
| Scopus            | Representation learning  | [LINK](Markdown%20Files/sc%20representation%20learning.md)       |
